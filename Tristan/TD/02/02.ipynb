{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49849907  0.54109015]\n",
      "[[ 3.12693622 -0.62851986]\n",
      " [-0.62851986  6.9706728 ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Array 'mean' must be a vector of length 6.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(class_mean)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(class_cov)\n\u001b[1;32m---> 90\u001b[0m \u001b[43mlikelihood_of_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_cov\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 73\u001b[0m, in \u001b[0;36mlikelihood_of_class\u001b[1;34m(feature, class_mean, class_covar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlikelihood_of_class\u001b[39m(\n\u001b[0;32m     63\u001b[0m     feature: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     64\u001b[0m     class_mean: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     65\u001b[0m     class_covar: np\u001b[38;5;241m.\u001b[39mndarray\n\u001b[0;32m     66\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    Estimate the likelihood that a sample is drawn\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    from a multivariate normal distribution, given the mean\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    and covariance of the distribution.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_covar\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# assuming we have a k-dimensional data\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_multivariate.py:397\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.__call__\u001b[1;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a frozen multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    See `multivariate_normal_frozen` for more information.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultivariate_normal_frozen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_multivariate.py:903\u001b[0m, in \u001b[0;36mmultivariate_normal_frozen.__init__\u001b[1;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a frozen multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    899\u001b[0m \n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m \u001b[38;5;66;03m# numpy/numpydoc#87  # noqa: E501\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist \u001b[38;5;241m=\u001b[39m multivariate_normal_gen(seed)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_object \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 903\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_singular \u001b[38;5;241m=\u001b[39m allow_singular \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_object\u001b[38;5;241m.\u001b[39m_allow_singular\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m maxpts:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_multivariate.py:414\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters\u001b[1;34m(self, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_parameters_Covariance(mean, cov)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Before `Covariance` classes were introduced,\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m# `multivariate_normal` accepted plain arrays as `cov` and used the\u001b[39;00m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;66;03m# following input validation. To avoid disturbing the behavior of\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# `multivariate_normal` when plain arrays are used, we use the\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;66;03m# original input validation here.\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m     dim, mean, cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters_psd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;66;03m# After input validation, some methods then processed the arrays\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# with a `_PSD` object and used that to perform computation.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;66;03m# To avoid branching statements in each method depending on whether\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;66;03m# `cov` is an array or `Covariance` object, we always process the\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;66;03m# array with `_PSD`, and then use wrapper that satisfies the\u001b[39;00m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;66;03m# `Covariance` interface, `CovViaPSD`.\u001b[39;00m\n\u001b[0;32m    421\u001b[0m     psd \u001b[38;5;241m=\u001b[39m _PSD(cov, allow_singular\u001b[38;5;241m=\u001b[39mallow_singular)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_multivariate.py:471\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters_psd\u001b[1;34m(self, dim, mean, cov)\u001b[0m\n\u001b[0;32m    468\u001b[0m     cov \u001b[38;5;241m=\u001b[39m cov\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a vector of length \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    472\u001b[0m                      dim)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cov\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    474\u001b[0m     cov \u001b[38;5;241m=\u001b[39m cov \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(dim)\n",
      "\u001b[1;31mValueError\u001b[0m: Array 'mean' must be a vector of length 6."
     ]
    }
   ],
   "source": [
    "# Author: \n",
    "# Date:\n",
    "# Project: \n",
    "# Acknowledgements: \n",
    "#\n",
    "from tools import load_iris, split_train_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def gen_data(\n",
    "    n: int,\n",
    "    locs: np.ndarray,\n",
    "    scales: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Return n data points, their classes and a unique list of all classes, from each normal distributions\n",
    "    shifted and scaled by the values in locs and scales\n",
    "    '''\n",
    "    data = norm.rvs(locs,scales,size=(n,len(locs)))\n",
    "    labels = []\n",
    "    classes = []\n",
    "    for i in range(len(locs)):\n",
    "        classes.append(i)\n",
    "        for j in range(len(data)):\n",
    "            labels.append(i)\n",
    "\n",
    "\n",
    "    return np.array(data),np.array(labels),np.array(classes)\n",
    "\n",
    "\n",
    "def mean_of_class(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    selected_class: int\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Estimate the mean of a selected class given all features\n",
    "    and targets in a dataset\n",
    "    '''\n",
    "    selected_features = features[targets==selected_class] \n",
    "    mu = np.mean(selected_features,0)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def covar_of_class(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    selected_class: int\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Estimate the covariance of a selected class given all\n",
    "    features and targets in a dataset\n",
    "    '''   \n",
    "    selected_features = features[targets==selected_class]\n",
    "    cov = np.cov(selected_features,rowvar=False)\n",
    "    return cov\n",
    "\n",
    "\n",
    "def likelihood_of_class(\n",
    "    feature: np.ndarray,\n",
    "    class_mean: np.ndarray,\n",
    "    class_covar: np.ndarray\n",
    ") -> float:\n",
    "    '''\n",
    "    Estimate the likelihood that a sample is drawn\n",
    "    from a multivariate normal distribution, given the mean\n",
    "    and covariance of the distribution.\n",
    "    '''\n",
    "\n",
    "    p = multivariate_normal(feature,class_mean,class_covar) # assuming we have a k-dimensional data\n",
    "    return p\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "features,targets,classes = gen_data(50, [-1, 1], [np.sqrt(5), np.sqrt(5)])\n",
    "(train_features, train_targets), (test_features, test_targets)\\\n",
    "    = split_train_test(features, targets, train_ratio=0.8)\n",
    "# print(mean_of_class(train_features,test_features,0))\n",
    "\n",
    "# print(covar_of_class(train_features,test_features,0))\n",
    "class_mean = mean_of_class(train_features, train_targets, 0)\n",
    "class_cov = covar_of_class(train_features, train_targets, 0)\n",
    "print(class_mean)\n",
    "print(class_cov)\n",
    "likelihood_of_class(train_features[0:3],class_mean,class_cov)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (40,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m (train_features, train_targets), (test_features, test_targets)\\\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;241m=\u001b[39m split_train_test(features, targets, train_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m    107\u001b[0m class_mean \u001b[38;5;241m=\u001b[39m mean_of_class(train_features, train_targets, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m class_cov \u001b[38;5;241m=\u001b[39m \u001b[43mcovar_of_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m class_cov\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# print(classes)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# maximum_likelihood(train_features,train_targets,test_features,classes)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 56\u001b[0m, in \u001b[0;36mcovar_of_class\u001b[1;34m(features, targets, selected_class)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcovar_of_class\u001b[39m(\n\u001b[0;32m     48\u001b[0m     features: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     49\u001b[0m     targets: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     50\u001b[0m     selected_class: \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m     51\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    Estimate the covariance of a selected class given all\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    features and targets in a dataset\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m   \n\u001b[1;32m---> 56\u001b[0m     selected_features \u001b[38;5;241m=\u001b[39m features[\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mselected_class\u001b[49m]\n\u001b[0;32m     57\u001b[0m     cov \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(selected_features,rowvar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cov\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (40,) (2,) "
     ]
    }
   ],
   "source": [
    "# Author: \n",
    "# Date:\n",
    "# Project: \n",
    "# Acknowledgements: \n",
    "#\n",
    "from tools import load_iris, split_train_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def gen_data(\n",
    "    n: int,\n",
    "    locs: np.ndarray,\n",
    "    scales: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Return n data points, their classes and a unique list of all classes, from each normal distributions\n",
    "    shifted and scaled by the values in locs and scales\n",
    "    '''\n",
    "    data = norm.rvs(locs,scales,size=(n,len(locs)))\n",
    "    labels = []\n",
    "    classes = []\n",
    "    for i in range(len(locs)):\n",
    "        classes.append(i)\n",
    "        for j in range(len(data)):\n",
    "            labels.append(i)\n",
    "\n",
    "\n",
    "    return np.array(data),np.array(labels),np.array(classes)\n",
    "\n",
    "\n",
    "def mean_of_class(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    selected_class: int\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Estimate the mean of a selected class given all features\n",
    "    and targets in a dataset\n",
    "    '''\n",
    "    selected_features = features[targets==selected_class] \n",
    "    mu = np.mean(selected_features,0)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def covar_of_class(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    selected_class: int\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Estimate the covariance of a selected class given all\n",
    "    features and targets in a dataset\n",
    "    '''   \n",
    "    selected_features = features[targets==selected_class]\n",
    "    cov = np.cov(selected_features,rowvar=False)\n",
    "    return cov\n",
    "\n",
    "\n",
    "def likelihood_of_class(\n",
    "    feature: np.ndarray,\n",
    "    class_mean: np.ndarray,\n",
    "    class_covar: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Estimate the likelihood that a sample is drawn\n",
    "    from a multivariate normal distribution, given the mean\n",
    "    and covariance of the distribution.\n",
    "    '''\n",
    "\n",
    "    p = norm.pdf(feature,class_mean,class_covar) # assuming we have a 1-dimensional input\n",
    "    return p\n",
    "\n",
    "\n",
    "def maximum_likelihood(\n",
    "    train_features: np.ndarray,\n",
    "    train_targets: np.ndarray,\n",
    "    test_features: np.ndarray,\n",
    "    classes: list\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Calculate the maximum likelihood for each test point in\n",
    "    test_features by first estimating the mean and covariance\n",
    "    of all classes over the training set.\n",
    "\n",
    "    You should return\n",
    "    a [test_features.shape[0] x len(classes)] shaped numpy\n",
    "    array\n",
    "    '''\n",
    "    means, covs = [], []\n",
    "    for class_label in classes:\n",
    "        means.append(mean_of_class(train_features,train_targets,class_label))\n",
    "        covs.append(covar_of_class(train_features,train_targets,class_label))\n",
    "\n",
    "    print(means)\n",
    "    print(covs)\n",
    "    likelihoods = []\n",
    "    for i in range(test_features.shape[0]):\n",
    "        likelihoods.append(likelihood_of_class(train_features[i],means,covs))\n",
    "    return np.array(likelihoods)\n",
    "\n",
    "\n",
    "features,targets,classes = gen_data(50, [-1,1], [np.sqrt(5),np.sqrt(5)])\n",
    "(train_features, train_targets), (test_features, test_targets)\\\n",
    "    = split_train_test(features, targets, train_ratio=0.8)\n",
    "class_mean = mean_of_class(train_features, train_targets, 1)\n",
    "class_cov = covar_of_class(train_features, train_targets, [0,1])\n",
    "class_cov\n",
    "# print(classes)\n",
    "# maximum_likelihood(train_features,train_targets,test_features,classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall match count (c): 3\n",
      "Class counts: {0: 1, 1: 2, 2: 1}\n",
      "Class indices: {0: [0], 1: [1, 3], 2: [2]}\n",
      "Match counts per class: {0: 1, 1: 2, 2: 0}\n"
     ]
    }
   ],
   "source": [
    "y_c = [0, 1, 2, 1]\n",
    "y_c_hat = [0, 1, 1, 1]\n",
    "\n",
    "c = 0\n",
    "class_counts = {}\n",
    "match_counts = {}\n",
    "class_indices = {}\n",
    "\n",
    "for i in range(len(y_c)):\n",
    "    _class = y_c[i]\n",
    "\n",
    "    # Increment the overall match count\n",
    "    if _class == y_c_hat[i]:\n",
    "        c += 1\n",
    "    \n",
    "    # Track the count of each class\n",
    "    if _class in class_counts:\n",
    "        class_counts[_class] += 1\n",
    "    else:\n",
    "        class_counts[_class] = 1\n",
    "\n",
    "    # Track the indices of each class\n",
    "    if _class in class_indices:\n",
    "        class_indices[_class].append(i)\n",
    "    else:\n",
    "        class_indices[_class] = [i]\n",
    "\n",
    "    # Track the count of matches for each class\n",
    "    if _class in match_counts:\n",
    "        if _class == y_c_hat[i]:\n",
    "            match_counts[_class] += 1\n",
    "    else:\n",
    "        match_counts[_class] = 1 if _class == y_c_hat[i] else 0\n",
    "\n",
    "print(\"Overall match count (c):\", c)\n",
    "print(\"Class counts:\", class_counts)\n",
    "print(\"Class indices:\", class_indices)\n",
    "print(\"Match counts per class:\", match_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_c = [0, 1, 2, 1]\n",
    "y_c_hat = [0, 1, 1, 1]\n",
    "\n",
    "# Initialize variables to track classes, counts, and matches\n",
    "class_counts = []\n",
    "match_counts = []\n",
    "\n",
    "# Iterate through the classes in y_c\n",
    "for i in range(len(y_c)):\n",
    "    _class = y_c[i]\n",
    "\n",
    "    # Ensure there are enough entries in class_counts and match_counts\n",
    "    while len(class_counts) <= _class:\n",
    "        class_counts.append(0)\n",
    "        match_counts.append(0)\n",
    "\n",
    "    # Track the count of each class\n",
    "    class_counts[_class] += 1\n",
    "\n",
    "    # Track the count of matches for each class\n",
    "    if _class == y_c_hat[i]:\n",
    "        match_counts[_class] += 1\n",
    "\n",
    "class_counts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio match_count / x_count for each unique x: [0.0, 0.5, 0.6666666666666666, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Given lists\n",
    "x = [1, 2, 2, 3, 1, 2, 4, 3]\n",
    "y = [1, 3, 2, 3, 4, 2, 4, 3]\n",
    "\n",
    "# Find the maximum value in x to determine the size of the lists\n",
    "max_value = max(x)\n",
    "\n",
    "# Initialize lists to store counts and ratios\n",
    "x_count = [0] * (max_value + 1)\n",
    "match_count = [0] * (max_value + 1)\n",
    "ratio = [0.0] * (max_value + 1)\n",
    "\n",
    "# Single loop to populate the lists and calculate the ratios\n",
    "for i in range(len(x)):\n",
    "    # Update the count of occurrences for x[i]\n",
    "    x_index = x[i]\n",
    "    x_count[x_index] += 1\n",
    "    \n",
    "    # Update the match count if x[i] == y[i]\n",
    "    if x[i] == y[i]:\n",
    "        match_count[x_index] += 1\n",
    "    \n",
    "    # Calculate the running ratio for x[i]\n",
    "    ratio[x_index] = match_count[x_index] / x_count[x_index]\n",
    "\n",
    "# Return only the ratio list\n",
    "print(\"Ratio match_count / x_count for each unique x:\", ratio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
